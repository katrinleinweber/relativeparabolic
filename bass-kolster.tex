The next theorem is a relative version of the so called Bass---Kolster decomposition (cf.~\cite[Theorem~2.1]{St78}).
\begin{thm}\label{thm:BassKolster}
Let $\Phi$ be a classical root system of rank $\ell\geqslant2$, let $R$ be an arbitrary commutative ring and $I$ be an ideal, satisfying one of the following assumptions:
\[\begin{array}{l@{\quad}l@{\quad}l@{\quad}c}
\Phi = \rA_\ell,\ \ell\geqslant 2, & \sr(I) \leqslant \ell; \\
\Phi = \rC_\ell,\ \ell\geqslant 2, & \sr(I) \leqslant 2\ell-1; \\
\Phi = \rB_\ell, \rD_\ell,\ \ell\geqslant 3, & \asr(I) \leqslant \ell-1.
\end{array}\]
Then the principal congruence subgroup $\G(\Phi,R,I)$ admits the following relative version of Bass---Kolster decomposition:
\[ \G(\Phi,R,I)=  \U(\Phi^+,I) \cdot \U(\Phi^-,I) \cdot Z \cdot \U(\Sigma_1^-\setminus\{-\alpha_\mathrm{max}\},I) \cdot \U(\Sigma_1,I) \cdot \G(\Delta_1,R,I), \]
where $Z=\left\{ z_{-\alpha_\mathrm{max}}(r,1)\ \middle|\ r\in I \right\}$.
\end{thm}
\begin{proof}

Let $g$ be an element of $\G(\Phi, R, I)$. Set $v=g \cdot v^+\in\Ums(n, I)$. 
Notice that in each case it suffices to find $g' \in \U(\Phi^-, I) \cdot \U(\Phi^+, I) \cdot g$ such that 
\begin{equation} \label{eq1} (g'\cdot v^+)_{1} = 1 + s \text{ and } (g'\cdot v^+)_{\varpi\ssub{1}-\alpha\ssub{max}} = s\ \text{for some}\ s\in I. \end{equation}
Indeed, set $g'' = z_{-\alpha\ssub{max}}(-s, 1) \cdot g'$.
Obviously, one has $(g''\cdot v^+)_1 = 1$, $(g''\cdot v^+)_{\varpi\ssub{1}-\alpha\ssub{max}}=0$ and the conclusion of the theorem follows from Lemma~\ref{lemma:Chevalley-Matsumoto}.

\textsc{Case $\Phi=\rA_\ell$, $n=\ell + 1$.}
%Set $v=(1+v_1,v_2,\ldots,v_\ell,v_{\ell+1})^t\in\Ums(\ell+1,R,I)$.
Thanks to the relative stable rank condition one can add suitable multiples of the last component $v_{\ell+1}$ to the first $\ell$ components of $v$ so that the upper
$\ell$ coefficients of the resulting vector $v'$ form an $I$-unimodular column of length $\ell$.
Now multiplying $v'$ by a suitable $y\in \U(\Sigma_\ell^-, I)$ we obtain equalities~\ref{eq1}.

\textsc{Case $\Phi=\rC_\ell$, $n=2\ell$.}
Notice that column $(v_1,\ldots, v_{-2}, v_{-1}^2)^t$ is also $I$-unimodular.
Applying condition $\sr(I)\leq 2\ell-1$ we find $c_1, c_2, \ldots, c_{-2} \in I \cdot v_{-1}$ such that upper $2\ell -1$ components of $v'=(v_1 + c_1 v_{-1}, \ldots, v_{-2} + c_{-2}v_{-1}, v_{-1})^t$ form an $I$-unimodular column.
By the choice of $c_i$ we can find suitable $d\in I$ such that $h_1 \cdot v = v'$ for
\[ h_1 = x_{1,-1}(c_1 + d) \cdot \prod_{i=2}^{-2} x_{i,-1}(c_i) \in \U(\Sigma_1^-, I). \]

We can find $f_1, f_2,\ldots, f_{-2} \in R$ such that $f_1v'_1+\sum_{i=2}^{-2} f_i v'_i = 1$.
%TODO: Determine exact sign
Set $\xi = v''_1-v''_{-1}-1 \in I$,
\[ h_2 = x_{-1,1}\biggl(\xi f_1 \pm \sum_{i=2}^\ell v_1' \xi^2 f_i f_{-i}\biggr) \cdot \prod_{i=2}^{-2} x_{-1,i}(\xi f_i) \in \U(\Sigma_1, I). \]
Direct computation shows that $v'' = h_2 \cdot v'$ satisfies equalities~\ref{eq1}.

%Now we can assume that the first $2\ell-1$ entries of $v$ are unimodular and find $c_1,\ldots,c_{-2}\in I$ such that $c_1v_1+\ldots+c_{-2}v_{-2}=(v_1-1)-v_{-1}$. Add $c_{-i}v_i$ to $v_{-1}$, $i=2,\ldots,\ell$:
%\[ (v_1,v_2\ldots,v_\ell,v_{-\ell},\ldots,v_{-2},v_{-1})^t\longmapsto (v_1,v'_2\ldots,v'_\ell,v_{-\ell},\ldots,v_{-2},v'_{-1})^t. \]
%Then add $c_iv_i'=c_i(v_1+c_{-i}v_{-i})$, $i=2,\ldots,\ell$ to the last entry:
%\[ v_1\longmapsto v_1,\quad v'_{-1}\longmapsto v_{-1}+\sum_{i=2}^\ell c_{-i}v_{-i}+\sum_{i=2}^\ell c_i(v_i+c_{-i}v_1)=v''_{-1}. \]
%Next add $\left(c_1-\sum_{i=2}^\ell c_ic_{-i}\right)v_1$ to $v''_{-1}$ to get $v_1-1$ in position $-1$.
%Again, as in case of $\rA_n$, apply $z_\gamma(1-v_1,1)$ with $\gamma=-\alpha_\mathrm{max}$, to get $1$ as the first entry and $0$ as the last.

\textsc{Case $\Phi=\rD_\ell$, $n= 2\ell$.} 
By Lemma~\ref{lemma:asrUnip} we can find $h_1\in \U(\Sigma^+_\ell, I)$ such that the upper half $v'_+$ of $v'=h_1 \cdot v$ is $I$-unimodular.
Since $\sr(I)\leq \ell-1$ we can find $c_1$, $c_3, \ldots c_\ell \in I$ such that $(v''_1, v''_3, \ldots, v''_\ell) \in \Ums(\ell-1, I)$, where
\[ v''=h_2 \cdot x_{1,2}(c_1) \cdot v', \quad h_2=\prod_{i=3}^\ell x_{i,2}(c_i). \]

We can find $f_1, f_3,\ldots, f_\ell \in R$ such that $f_1v''_1+\sum_{i=3}^\ell f_i v''_{i} = 1$.
As before, set
\[ \xi = v''_1-v''_{-2}-1 \in I, \quad h_3 = x_{-2,1}(\xi f_1) \cdot \prod_{i=3}^\ell x_{-2,i}(\xi f_i), \quad v'''=h_3 \cdot v''. \]
%Clearly, $v'''_{-2}=v'''_1-1$, therefore for $v_4 = z_{-\alpha_{max}}(-v'''_{-2}, 1) \cdot v'''$ one has $v^4_1 = 1$, as required.
Clearly, $t_{1,2}(c_1) \cdot h_1 \in \U(\Phi^+, I)$, $ h_3 \cdot h_2 \in \U(\Phi^-, I)$ and $v'''$ satisfies \ref{eq1}.

\textsc{Case $\Phi=\rB_\ell$, $n=2\ell+1$.} Subdivide $v\in \Ums(2\ell+1, I)$ as $v=(v_+, v_0, v_-)\in R^\ell\times R\times R^\ell$.
Denote by $J\leq I$ the ideal spanned by components of $v_-$.
Since $\sr(I/J)\leq \ell$ we can find $c_1,\dots,c_\ell\in I$ such that for $v' = h \cdot v$, $h = \prod_{i=1}^\ell x_{i,0}(c_i) \in \U(\Phi^+, I)$
one has $\bar{v'}_+=(\bar{v'_1},\ldots, \bar{v'_\ell}) \in \Ums(\ell, I/J)$ and, therefore, $(v'_+, v'_-) \in \Ums(2\ell, I)$.
Now the proof can be finished by repeating the argument for the case $\Phi=\rD_\ell$ (applied to the subset of long roots of $\rB_\ell$).
%(clearly, the maximal root of $\rD_\ell$ maps to the maximal root of $\rB_\ell$ under the natural embedding $\rD_\ell\subseteq\rB_\ell$). 
\end{proof}

It is easy to see that the proof of the above theorem is effective and gives an estimate of the total number of elementary root unipotents involved in the decomposition.
\begin{cor}
In the assumptions and notation of Theorem~\ref{thm:BassKolster} every element of $\G(\Phi,R,I)$ 
can be factored into a product of one element of $\G(\Delta_1,R,I)$ one element of $Z$ and at most $4(|\Phi^+| - |\Delta_1^+|)-1$ elementary root unipotents $x_\alpha(s)$ of level $I$. \end{cor}
\begin{proof}
The above estimates can be obtained by a careful analysis of the proof of the previous theorem.
Cases $\Phi=\rA_\ell, \rC_\ell$ are immediate.
In the case $\Phi=\rD_\ell$ the proof of Theorem~\ref{thm:BassKolster} implies that
\begin{multline}\nonumber
\G(\Phi,R,I) =  \U(\Sigma_\ell,I) \cdot X_{\alpha_1}(I) \cdot \U(\Sigma_2^-\cap\Delta_1,I) \cdot X_{-\alpha\ssub{\mathrm{max}}}(I) \cdot Z  \cdot \\ \cdot \U(\Sigma_1^-,I) \cdot \U(\Sigma_1,I) \cdot \G(\Delta_1,R,I).
\end{multline}
We can present an element $g$ of $\U(\Sigma_\ell, I)$ as a product of $g_1 \in \U(\Sigma_{\{1,2\}} \cap \Sigma_\ell)$ and $g_2\in \U(\Delta_{\{1,2\}}\cap \Sigma_\ell)$.
An examination of the extended Dynkin diagram of $\rD_\ell$ implies that $g_2$ either centralizes or normalizes all factors of the above decomposition (except the last one) and therefore can be moved to the right until it is consumed by $\G(\Delta_1)$.
On the other hand, $g_1$ is a product of at most $2\ell-3$ elementary unipotents, while the width of $\U(\Sigma_1^\pm, I)$ and $\U(\Sigma_2^-\cap\Delta_1)$ in elementary unipotents does not exceed $2\ell-2$ and $2\ell-4$, respectively.
Summing up these upper bounds we obtain
$$(2\ell-3) + 1 + (2\ell - 4) + 1 + 2\cdot (2\ell - 2) = 8\ell - 9 = 4(|\rD_\ell| - |\rD_{\ell-1}|) - 1.$$

The estimate in the case $\Phi=\rB_\ell$ can be obtained in a similar way. \end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:SL2width}]
Consider the case $\Phi=\rA_\ell$, $\sr(I)\leq 2$. First of all, notice that we can improve the estimate of the number of factors involved in Bass---Kolster decomposition.
Indeed, when performing the first step of the proof of Theorem~\ref{thm:BassKolster} it suffices to make only $2$ additions of $v_{\ell+1}$ (e.\,g. to $v_{1}$ and $v_2$) to make the first $\ell$ entries of $v'$ form a unimodular column.
In particular, $\G(\Phi, R, I)$ can be presented as a product of one element of $\G(\Delta_1, R, I)$, one element of $Z$ and $3\ell+1$ root unipotents $x_\alpha(s)$, $s\in I$.
The latter elements are contained in a product of $3\ell + 1$ copies of $\SL(2, R, I)$. Now the statement of the theorem follows by induction on $\ell$.

The proof in the case $\Phi=\rC_\ell$ is similar (notice that we use the exceptional isomorphism $\SL(2, R)\cong \Sp(2, R)$).
\end{proof}
